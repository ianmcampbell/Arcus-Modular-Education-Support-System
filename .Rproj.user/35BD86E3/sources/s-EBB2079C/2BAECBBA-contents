---
title: "Two-Sample _t_ Test"
output: learnr::tutorial
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
options(digits = 3, scipen = 9999)
if(!require(learnr)){install.packages("learnr")}
library(learnr)
Input =("
Group Value
2pm    69    
2pm    70    
2pm    66    
2pm    63    
2pm    68    
2pm    70    
2pm    69    
2pm    67    
2pm    62    
2pm    63    
2pm    76    
2pm    59    
2pm    62    
2pm    62    
2pm    75    
2pm    62    
2pm    72     
2pm    63    
5pm    68
5pm    62
5pm    67
5pm    68
5pm    69
5pm    67
5pm    61
5pm    59
5pm    62
5pm    61
5pm    69
5pm    66
5pm    62
5pm    62
5pm    61
5pm    70
")
height = read.table(textConnection(Input),header=TRUE)
names(height) <- c("section", "inches")
tt_height <- t.test(inches ~ section, 
                    data = height,
                    var.equal = TRUE,
                    conf.level = 0.95)

```

## Background

There are several statistical tests that use the _t_ distribution and can be called _t_ tests. One is Student's _t_ test for two samples, named after "Student," the pseudonym William Gosset used to hide his employment by the Guinness brewery in the early 1900s (they had a rule that their employees weren't allowed to publish, and Guinness didn't want other employees to know that they were making an exception for Gosset). Student's _t_ test for two samples compares the means in two groups.

```{r aa, echo=FALSE}
question("What might have been one of Student's favorite pasttimes?",
      answer("Drinking beer", correct = TRUE),
      answer("Working as a hairdresser"),
      answer("Flying to Jupiter's moons"),
      answer("Going to school full time")
)
```

### Two-sample _t_ Test Variables

>* One [scalar (a.k.a. "measurement") variable](http://www.biostathandbook.com/variabletypes.html#nominal)     
* One nominal variable with only two categories or two categories that you have selected. You can also use a binary variable here as it is functionally a nominal variable with two categories. 

Student's _t_ test for two samples shows whether the means of the measurement variable are significantly different in two groups. 

It is mathematically identical to a one-way ANOVA with two categories; but because comparing the means of two samples is such a common experimental design, and because the _t_ test is familiar to many more people than the ANOVA, we treat the two-sample _t_ test separately.

```{r a, echo=FALSE}
question("What other test does the two-sample _t_ test NOT resemble?",
         answer("a one-sample _t_ test"),
         answer("a one-way ANOVA with only two categories"),
         answer("a paired _t_ test"),
         answer("a linear regression model", correct = TRUE)
)
```


### Null and Alternative Hypotheses

>* **H<sub>0</sub>**: The means of the measurement variable are equal in the two groups.     
* **H<sub>A</sub>** (2-sided): The means of the measurement variable are not equal in the two groups.     
* **H<sub>A</sub>** (1-sided): The mean of the measurement variable is higher (specifically---or lower specifically, but not either-or because that would be a 2-sided test) in one of the groups.

```{r bb, echo=FALSE}
question("What is NOT an example of a 1-sided null hypothesis?",
         answer("It usually takes less than one hour to make pie dough"),
         answer("The average monthly electric bill in Philadelphia, PA is $92", correct = TRUE),
         answer("The average monthly electric bill in Philadelphia, PA is less than $100"),
         answer("The average monthly electric bill in Philadelphia, PA is more than $100")
)
```

### Examples of the Null and Alternative Hypotheses

You have become curious about the sizes of adult children's feet. Are right feet the same as left feet?

There are two variables in that question. 

```{r two-vars, echo=FALSE}
question("What are the two variables?",
         answer("right feet and left feet"),
         answer("foot size and type of person (adult vs. child)"),
         answer("foot size and foot type (left vs. right)", correct = TRUE)
)
```

In fall 2004, students in the 2 p.m. section of John McDonald's Biological Data Analysis class had an average height of 66.6 inches, while the average height in the 5 p.m. section was 64.6 inches. Are the average heights of the two sections significantly different? 

First, let's look at the data. It's been loaded in `height` for you. Use `head` to look at it, then change the variable names. There are lots of ways to change variable names in R. In this case, try simply stating `names(height) <- c("section", "inches")`. Then type `names(height)` to see if it worked. 

```{r heightnames, exercise = TRUE}

```
```{r heightnames-solution}
head(height)
names(height) <- c("section", "inches")
names(height)
```

The null hypothesis and alternatives are, therefore

>* **Example H<sub>0</sub>**: "Mean heights in the two sections are the same."     
* **Example H<sub>A</sub>** (2-sided): "Mean heights in the two sections are not the same."     
* **Example H<sub>A</sub>** (1-sided, version 1): "Mean height in the 2 pm section is higher than in the 5 pm section."     
* **Example H<sub>A</sub>** (1-sides, version 2): "Mean height in the 5 pm section is higher than in the 2 pm section."     

We'll use aptly named function `t.test` to see if the means are NOT the same in the two sections. Pass it the formula `section ~ inches`, then `data = ` the data set name, then two parameters: `alternative` set to `two-sided` and `conf.level` set to the usual 0.95.


```{r height-t-test, exercise = TRUE}

```
```{r height-t-test-solution}
t.test(inches ~ section, # the nominal variable with two options
       data = height,    # the measurement or scalar variable
       alternative = "two.sided", 
       conf.level = 0.95)
```

According to the output, _p_ is `r round(tt_height$p.value, 2)`. We would reject the null hypothesis if _p_ < .05 (as per usual), but in this case, it's not. We cannot reject the null hypothesis that mean heights in the two groups are the same. Note that we have not proven that the null hypothesis is true, just that we can't say it's _not_ true. 

To report the results of a two-sample _t_ test, you would provide the test statistic (_t_), the [degrees of freedom]() (df), and the _p_ value (_p_) in a sentence like this: "based on the results of a _t_ test (_t_ = `r round(tt_height$statistic[[1]], 2)`, df = `r round(tt_height$parameter[[1]], 2)`, _p_ = `r round(tt_height$p.value[[1]], 2)), we do not reject the null hypothesis that the two group means are the same." 

## More about the Output

Run `t.test` again on the same data, but this time store the result in `tt_height`. 

```{r tt_again, exercise = TRUE}

```
```{r tt_again-solution}
tt_height <- t.test(inches ~ section, # the nominal variable with two options
                    data = height,    # the measurement or scalar variable
                    alternative = "two.sided", 
                    conf.level = 0.95)
```

In R, everything is an object. What does this object look like?

```{r tt_look_like, exercise = TRUE}

```
```{r tt_look_like-solution}
tt_height
```

What is its structure? (Hint: use R's `str` function to find out.)

```{r tt_str, exercise = TRUE}

```
```{r tt_str-solution}
str(tt_height)
```

That's interesting. What looked like a paragraph of output was actually a list! Try accessing elements of the list, say, `method`.

```{r tt_method, exercise = TRUE}

```
```{r tt_method-solution}
tt_height$method
```

You can use output very nicely in your [reproducible Markdown text]() by calling it within text while you write. For instance, you might write, "I just did a " and then type a tic-mark (likely under the tilde in the upper left of your keyboard, looks like this: \`, not to be confused with a single quote), then `r tt_height$method`, followed by a closing tic-mark. The output would be 

>I just did a `r tt_height$method`. 

Let's go through the _t_ test outputted ("put out"?) list one by one.


### Statistic

Access `statistic` within `tt_height`.

```{r access_statistic, exercise = TRUE}

```
```{r access_statistic-solution}
tt_height$statistic
```

```{r statist_output, echo=FALSE}
question("What is the statistic?",
         answer("66.55556"),
         answer("1.310886", correct = TRUE),
         answer("31.17529"),
         answer("0")
)
```







### Assumptions

**Normal distribution**. Normality is a common assumption, and the _t_ test is no exception. It assumes that the observations within each group are normally distributed. If the distribution is symmetrical, such as a flat or bimodal distribution, you may still be able to proceed, though: the one-sample _t_ test is not all _that_ sensitive to non-normality; you will get accurate estimates of the P value, even with small sample sizes.

Nevertheless, a severely skewed distribution can give you too many false positives unless the sample size is large (above 50 or so). If your data is severely skewed _and_ you have a small sample size, you should try a data transformation to make it less skewed. 

With large sample sizes (> 50), the one-sample _t_ test will give accurate results even with severely skewed data.

```{r d, echo=FALSE}
question("Which situation will not result in reliable results of a one-sample _t_ test?",
         answer("large sample size"),
         answer("skewed data"),
         answer("small sample size"),
         answer("skewed data and a small sample size", correct = TRUE)
)
```

### Interpretation

To report significant results, say something like “Mean score for Variable A was significantly different from a default value of 75."

## Practice: Sodium Levels

In the following example, Brendon Small asked his students keep diaries of what they ate for a week, then calculate their daily sodium intake in milligrams.  As a first step in the analysis, he wanted to compare his students' mean sodium intake to the American Heart Association recommendation of 1500 mg (which is our new $\normalsize \mu$). 
 
A one-sample _t_ test can be conducted with the `t.test` function in the native stats package.  Conveniently, the output includes the mean of the sample, a confidence interval for that mean, and a P value for the _t_ test.

### Prepare Coding Environment

The data is already available in a tibble (a type of data frame that prints nicely to the screen when you call it by name) called `sodium`. 

Make sure you have installed the required packages. They are `psych`, `rcompanion`, `lsr`, `ggplot2`, and `tidyverse`.

```{r e, exercise = TRUE}

```
```{r e-solution}
if(!require(psych)){install.packages("psych")}
if(!require(rcompanion)){install.packages("rcompanion")}
if(!require(lsr)){install.packages("lsr")}
if(!require(ggplot2)){install.packages("ggplot2")}
if(!require(tidyverse)){install.packages("tidyverse")}
```

### Test Assumptions
 
We will use a histogram with an imposed normal curve to confirm data are approximately normal. First, though, let's just look at the data. We'll use functions from the `psych` package, so be sure to call `library(psych)` before calling the functions `headTail`, `str`, and `summary`, passing `sodium` to each of them. (Tip: Sometimes if I know I'll be passing data to several functions, I'll set it equal to a shorter name, here `xNa`, so I can just type `xNa` instead of the longer name.)

```{r f, exercise = TRUE}

```
```{r f-solution}
xNa <- sodium$Sodium
library(psych)
headTail(xNa)
str(xNa)
summary(xNa)
```

Use the function `plotNormalHistogram` from the `rcompanion` package to see if the data is approximately normally distributed. All the function requires is the variable with the sodium levels, `Sodium`. Make sure to put `rcompanion` into the library before calling `plotNormalHistogram`.

```{r g, exercise = TRUE}

```
```{r g-solution}
library(rcompanion)
plotNormalHistogram(xNa)
```

The shape isn't exactly normal, but it isn't badly skewed, either. Let's look at a normal quantile plot of the data. You don't have to store `sodium$Sodium` in the variable `xNa`, but I did. Then pass `xNa` to `qqnorm`. Evaluate the resulting plot. It needs a red line, so call `qqline` and pass it `xNa` and tell it to use `col` equal to "red".

```{r h, exercise = TRUE}

```
```{r h-solution}
qqnorm(xNa)
qqline(xNa, col = "red")
```

A perfectly normal distribution would have the dots exactly along the line. This is not perfectly normal, but it's close enough.


### Perform the _t_ Test

We've tested the assumptions and found that they have been met. Now we run the code for the _t_ test itself. Call the function `t.test` and pass it the following: the variable `Sodium`, `mu` equal to the hypothesized level against which we want to test the students' sodium levels (1500), and `conf.int` with the desired confidence interval. People usually like to see 95% confidence intervals, so set `conf.int` equal to 0.95. Then run the chunk and let's see what happens.

```{r i, exercise = TRUE}

```
```{r i-solution}
muNa <- 1500 # theoretical mean
t.test(xNa,
       mu = muNa,
       conf.int = 0.95)
```

A bunch of text and numbers. What does it all mean?

### Interpret the Output

`t.test` gives us lots of good information about our hypothesis test:

* It tells you which variable you passed it (in this case, `sodium$Sodium`)    
* It provides specific statistics: 
     * _t_ is -4.9053, which is where within a _t_ distribution our data mean would appear. Locations within the _t_ distribution dictate P's value
     * P is close to 0 (0.00009825)    
* Then the function tells you in plain English what to do with the information it just provided. Here, it says to reject the null hypothesis in favor of the alternative hypothesis that the "true mean is not equal to 1500."     
* Going one step further (because we asked it to), `t.test` provides the 95% confidence interval, the interval within which 95% of samples like this one's mean sodium would fall. That's between 1196.83 and 1378.17 with our data.     
* Finally, it gives us the sample estimate of the true population mean ("population" meaning the underlying population represented by our sample of students): 1287.5 grams of sodium.    

## More Practice: Words per Minute

You will find a dataset called `wpm` in memory. Let's perform a _t_ test using the data.

### Prepare the Coding Environment

Our prepations for this example analysis are the same as for the previous example: we'll use the same packages. Use the same code as for the previous _t_ test to make sure all the necessary packages have been loaded.

```{r j, exercise = TRUE}

```
```{r j-solution}
if(!require(psych)){install.packages("psych")}
if(!require(rcompanion)){install.packages("rcompanion")}
if(!require(lsr)){install.packages("lsr")}
if(!require(ggplot2)){install.packages("ggplot2")}
if(!require(tidyverse)){install.packages("tidyverse")}
```

Now have a look at the data. We are especially interested in the sample size. Copy `wpm$words_per_minute` to `xwpm` for brevity.

```{r k, exercise = TRUE}

```
```{r k-solution}
xwpm <- wpm$words_per_minute
library(psych)
headTail(xwpm)
str(xwpm)
summary(xwpm)
```

There are 16 observations, so we ought not to perform a _t_ test on this data if it is badly skewed. 

### Test Assumptions

As is typical for this sort of data, we use a histogram with an imposed normal curve to confirm data are approximately normal. We'll use functions as before from the `rcompanion` package, so be sure to call `library(rcompanion)` before calling the function `plotNormalHistogram` using `xwpm`.

```{r l, exercise = TRUE}

```
```{r l-solution}
xwpm <- wpm$words_per_minute
library(rcompanion)
plotNormalHistogram(xwpm)
```

This distribution is normal enough for a _t_ test, even though it is a little skewed. 

Let's look at a normal quantile plot of the data. Pass `wpm$words_per_minute` (or whatever you copied it to for brevity) to `qqnorm`. Evaluate the resulting plot. Let's have a green line this time. Call `qqline` and pass it `xwpm` and tell it to use `col` equal to "green".

```{r m, exercise = TRUE}

```
```{r m-solution}
qqnorm(xwpm)
qqline(xwpm, col = "green")
```

### Perform the _t_ Test

We've tested the assumptions and found that they have been met. Now we run the code for the _t_ test itself. We are interested in whether these students, in general, type faster than the typical 40 words per minute. Call the function `t.test` and pass it the following: the variable `xwpm`, `mu` equal to the hypothesized level against which we want to test the students' words per minute (set `muwpm <- 40`), and `conf.int` with the desired confidence interval. People usually like to see 95% confidence intervals, so set `conf.int` equal to 0.95. Then run the chunk and let's see what happens.

```{r n, exercise = TRUE}

```
```{r n-solution}
muwpm <- 40
t.test(xwpm,
       mu = muwpm,
       conf.int = 0.95)
```

### Interpret the Output

We performed the _t_ test by testing our students' average typing speed against the expected average of 40 words per minut.  _t_ is 6.925 with 15 degrees of freedom. The locations within the _t_ distribution dictate a P close to 0 (0.000004853) and a 95% confidence interval for `words_per_minute` ranging from 50.59948 to 60.02552. In plain English, we are advised that we can reject the null hypothesis that our students' typing speed is the same as the average 40 wpm and conclude that the true mean for the population represented by our sample of students is not equal to 40. In fact, we estimate the population mean to be 55.3125 words per minute. 

## Effect Size: How much of a Difference do we Care About?

Suppose you have a very large sample of students and find it statistically significant that they have a different typing speed from the average 40 words per minute. Suppose, too, that the mean for your sample is 41 words per minute. Is that an interesting difference? How much of a difference is interesting? What is a small, medium, or large effect size? 

The first problem is that small, medium, and large effect sizes mean different things depending on what you measure. Six words per minute when the average is 40 is a 15% change, whereas 6 grams of sodium out of 1500 is only a .4% change. How do we standardize the importance of changes?

### Cohen's _d_

Cohen’s _d_ can be used as an effect size statistic for a one-sample _t_ test.  Calculate Cohen's _d_ by taking the difference between the mean of the data (like 55.3125 wpm or 1287.5 grams of sodium) and $\normalsize \mu$, the default value or population estimate of the mean (like 40 wpm or 1500 grams of sodium), all divided by the standard deviation of the data (which you can get by using `sd(xwpm)` or `sd(xNa)` :

>$\large d = \frac{| \bar{x} - \mu |}{\sigma}$ 

Using the sodium example:

>$\large d = \frac{|1287.5 - 1500|}{193.7341} = 1.096864.$ 

Using the words-per-minute example:

>$\large d = \frac{|55.3125 - 40|}{8.844725} = 1.731258.$ 

But you don't have to do all that math. You don't even have to memorize the formula. R, of course, has a function that calculates it called `cohensD`. Call `cohensD` now and pass it the variable `sodium$Sodium` and the theoretical mean, 1500. First be sure to put `lsr` in the library.

```{r o, exercise = TRUE}

```
```{r o-solution}
library(lsr)
cohensD(sodium$Sodium, 1500)
```

Cohens _d_ for `sodium$Sodium` is 1.096864. What does that mean?

### Interpreting Cohen's _d_

Cohen's _d_ ranges from 0 to $\normalsize \infty$, with 0 indicating no effect: the mean equals $\normalsize \mu$.  Cohen’s d can be positive or negative depending on whether the mean is greater than or less than mu. Our sodium effect size is 1.096864 standard deviations from the mean.

#### Relating Cohen's _d_ to the Difference between the Theoretical and Sample Means

What's the standard deviation of `sodium$Sodium`?

```{r p, exercise = TRUE}

```
```{r p-solution}
sd(sodium$Sodium)
```
 
So the actual effect size we found in the _t_ test about sodium levels in students is `1.096864 * sd(sodium$Sodium)`. Calculate that and store it in the variable `sodium_effect`. Feel free to store `sodium$Sodium` in `xNa` so you can type it just once. Then print out the difference between the theoretical mean and the sample mean. 

```{r q, exercise = TRUE}

```
```{r q-solution}
xNa <- sodium$Sodium
(sodium_effect <- 1.096864 * sd(xNa))
1500 - mean(xNa)
```

By comparing the two values, we basically just checked our work and found it to be correct.

#### Relating Cohen's _d_ to Effect Size in the World at Large

But forget about the actual change in sodium. We used Cohen's _d_ to _standardize_ the effect size so we could compare the importance of the differences we found between sample words per minute (55.3125) and expected words per minute (40) and that between sample sodium intake (1287.5) grams and expected sodium intake (1500 grams). Which are the relative effect sizes?
 
A Cohen’s d of 0.5 suggests that the mean and $\normalsize \mu$ differ by one-half the standard deviation of the data. A Cohen’s _d_ of 1.0 suggests that the mean and $\normalsize \mu$ differ by one standard deviation of the data.

Rule of thumb about effect sizes: 

* Small effect = 0.2    
* Medium effect = 0.5    
* Large effect = 0.8    

To review, calculate the two Cohen's _d_'s for the two problems we worked above. Would you call them small, medium, or large effects?

```{r r, exercise = TRUE}

```
```{r r-solution}
cohensD(wpm$words_per_minute, muwpm)
cohensD(sodium$Sodium, muNa)
```

Both the effects we found are large (> .8)

## Graphing the Data against the Default (i.e. Expected) Value

Here is a box plot with the default value highlighted. This next code chunk isn't an exercise. It's an example of code you can use to report your findings. 

```{r s}
library(ggplot2)

# ggplot(data=sodium, 
#        aes(x = Instructor, y = Sodium)) +
#        geom_boxplot() +
#        geom_point(aes(x = 1, y = 1500), 
#                   colour="blue",
#                   size = 8,
#                   shape = "+") +
#        theme_bw() +
#        theme(axis.title = element_text(face = "bold")) +
#        theme(axis.text = element_text(face = "bold"))

```

Now use that code to create another box plot, this one for the words-per-minute data. Go ahead and improve on the plot design by adding a label for the y axis that isn't the variable name but rather the variable _label_. If you don't know how to do this, you can click on the Solution button and peek or you can do an internet search for "adding labels to my ggplot". There are several ways to accomplish this. And try changing the theme to minimal to see if you prefer the output.

```{r t, exercise = TRUE}

```
```{r t-solution}
# library(ggplot2)
# 
# ggplot(data=wpm, 
#        aes(x = Instructor, y = words_per_minute)) +
#        geom_boxplot() +
#        geom_point(aes(x = 1, y = 40), 
#                   colour="blue",
#                   size = 8,
#                   shape = "+") +
#        theme_minimal() +
#        theme(axis.title = element_text(face = "bold")) +
#        theme(axis.text = element_text(face = "bold")) +
#   labs(y = "Words per Minute")
```

## References

This lesson is heavily based with thanks on the works of John H. McDonald ([Handbook of Biological Statistics](http://www.biostathandbook.com/chigof.html)) and Salvatore S. Mangiafico ([R Companion to the Biostats Handbook](https://rcompanion.org/rcompanion/b_03.html)).
